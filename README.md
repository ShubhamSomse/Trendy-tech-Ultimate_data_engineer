# Trendy-tech-Ultimate_data_engineer
18-week accelerated roadmap following Sumeet Mittalâ€™s Trendy Tech Ultimate Data Engineering Program â€” hands-on implementation of PySpark, Databricks Lakehouse, Azure ADF, Delta Lake, Streaming (Kafka), Data Modeling, and CI/CD with real-world projects.

# ğŸš€ Trendy Tech Ultimate Data Engineer â€“ Hands-On Implementation (Oct 2025 â†’ Feb 2026)

This repository contains all my week-by-week hands-on work from the **Trendy Tech Ultimate Data Engineer Course** by Sumeet Mittal â€” executed on **Databricks Free Edition** and structured into an **18-week accelerated learning roadmap**.

Iâ€™m compressing the 7-month course into 4.5 months while balancing a full-time job â€” combining videos, hands-ons, SQL/DSA drills, and real Azure data-engineering projects.

---

## ğŸ§© Repository Structure

Each week = one folder with:
- ğŸ“’ **Databricks notebooks** for lecturesâ€™ hands-on  
- ğŸ§  **README.md** summarizing concepts, code snippets, and learnings  
- ğŸ“Š **Screenshots/Architecture diagrams**  
- ğŸ“˜ **SQL + DSA progress logs**


---

## ğŸ“… 18-Week Original Plan

| Week | Theme | Focus Highlights | Expected Output |
|------|--------|------------------|-----------------|
| **1** | Big Data & Foundations | Big Data ecosystem, Hadoop basics, DE architecture, setup repo | Repo init + first data flow notebook |
| **2** | Distributed Storage & HDFS | HDFS vs Cloud DL, replication, Linux basics | File ingestion simulation + ADLS mount |
| **3** | Distributed Processing â†’ Spark Entry | Spark internals, RDD basics, DAG visualization | RDD â†’ DF conversion + Spark UI demo |
| **4** | Spark Core APIs & Transformations | map, flatMap, joins, broadcast, cache | Join and repartition perf lab |
| **5** | DataFrames & Spark SQL | SparkSQL vs Hive, tables types, window funcs | Mini mart with DF & SparkSQL |
| **6** | Schema & File Formats | schema evolution, Parquet/Delta, read/write modes | File Consolidator project |
| **7** | Spark Architecture & Aggregations | cluster modes, window aggs optimization | Aggregation notebook |
| **8** | Perf Tuning I | partitions, bucketing, I/O formats | Perf comparison lab |
| **9** | Perf Tuning II + Catalyst | AQE, join strategies, plans explain | Tuning playbook + benchmarks |
| **10** | Azure Cloud Fundamentals | Azure RGs, Storage, Key Vault | Cloud setup notes + cost sheet |
| **11** | Databricks I | Lakehouse, Delta, Volumes, Autoloader COPY INTO | Mini-Medallion v1 pipeline |
| **12** | Databricks II | Lakeflow (DLT), Unity Catalog, Asset Bundles | Project #1 Batch Lakehouse |
| **13** | ADF I | LS/Datasets, parameterization, triggers | Orchestrated pipeline |
| **14** | ADF II | Event triggers, Key Vault, HTTP connectors | Event-triggered ADF flow |
| **15** | Data Modeling & SCD-2 | Dimensional modeling, SCD-2 MERGE | Fact-Dim model + Delta merge demo |
| **16** | Structured Streaming I | Sources/Sinks, output modes, triggers | Stream Bronzeâ†’Silver pipeline |
| **17** | Kafka Integration II | Kafka producer/consumer, replication + Spark integration | Project #2 Streaming ETL |
| **18** | Capstone + CI/CD + Mocks | Asset Bundles CI/CD, alerting, mock interviews | Final portfolio + resume update |

---

## ğŸ§  Focus Areas
- PySpark + Spark Optimization  
- Databricks Lakehouse (Delta, Unity, DLT)  
- Azure ADF + DevOps CI/CD  
- Kafka Streaming Integration  
- Data Modeling & SCD-2  
- SQL & DSA for DE Interviews  
- Real Azure End-to-End Projects  

---

## ğŸ› ï¸ Tools & Tech Stack
**Languages:** Python | SQL  
**Platforms:** Databricks Free Edition | Azure ADF | Azure DevOps  
**Frameworks:** Apache Spark, Delta Lake, Kafka, Iceberg  
**Modeling:** Star/Snowflake, SCD Type 2  
**Version Control:** Git + GitHub  

---

## ğŸ Timeline
| Start | End | Duration |
|--------|------|-----------|
| **13 Oct 2025** | **15 Feb 2026** | 18 Weeks (Accelerated) |

---

## ğŸŒŸ Author
**Shubham Somse**  
_Data Engineer | Azure Databricks | PySpark | ADF_  
ğŸ“ Pune, India  
ğŸ”— [LinkedIn](https://linkedin.com/in/ShubhamSomse)

---

> _â€œEach week, one concept. One notebook. One step closer to Tier-1.â€_

